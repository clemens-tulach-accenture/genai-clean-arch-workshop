{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a8d1967",
   "metadata": {},
   "source": [
    "# Cell 0 — Notebook Header / Info\n",
    "\"\"\"\n",
    "10_build_index.ipynb\n",
    "Ziel: Mini-RAG-Index über Regel-Markdowns bauen (Clean Architecture / Layering).\n",
    "Funktionen:\n",
    "- Regeln einlesen -> chunken -> Embeddings -> FAISS-Index -> Queries + Zitate\n",
    "Abhängigkeiten: faiss-cpu, sentence-transformers, numpy, pandas, tqdm, rank-bm25 (optional)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba49a0f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1 — Install (nur beim ersten Lauf nötig)\n",
    "import sys, subprocess, pkgutil\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if pkgutil.find_loader(p.split(\"==\")[0]) is None:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", p], check=False)\n",
    "\n",
    "pip_install([\n",
    "    \"faiss-cpu\",\n",
    "    \"sentence-transformers\",\n",
    "    \"rank-bm25\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"tqdm\",\n",
    "    \"pyyaml\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fec45f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2 — Imports\n",
    "import os, json, uuid, math, re, textwrap, pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "try:\n",
    "    from rank_bm25 import BM25Okapi\n",
    "    HAS_BM25 = True\n",
    "except:\n",
    "    HAS_BM25 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca67b94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3 — Konfiguration\n",
    "BASE_DIR = Path.cwd()\n",
    "RULES_DIR = BASE_DIR / \"10_rag\" / \"rules\"   # erwartet: *.md Regeldateien\n",
    "ARTIFACTS_DIR = BASE_DIR / \"10_rag\" / \"artifacts\"\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # klein, schnell\n",
    "CHUNK_TOKENS = 500     # Zielgröße pro Chunk (grob, ohne echtes Tokenizer-Counting)\n",
    "OVERLAP_TOKENS = 60    # Überlappung zw. Chunks\n",
    "TOP_K = 5              # Standard Top-K für Suchergebnisse\n",
    "\n",
    "INDEX_PATH = ARTIFACTS_DIR / \"faiss.index\"\n",
    "META_PATH  = ARTIFACTS_DIR / \"chunks_meta.jsonl\"\n",
    "BM25_PATH  = ARTIFACTS_DIR / \"bm25_corpus.jsonl\"   # optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65ac83",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4 — Regeldateien prüfen & ggf. Demo-Regeln anlegen\n",
    "SAMPLE_RULES = {\n",
    "\"clean_architecture.md\": \"\"\"\n",
    "# Clean Architecture (Kurz)\n",
    "- Domain kennt keine Infrastruktur-Details.\n",
    "- Use Cases/Services enthalten Business-Logik.\n",
    "- Adapter/Controller nur Ein-/Ausgabe, kein Fachwissen.\n",
    "\"\"\",\n",
    "\"layered_architecture.md\": \"\"\"\n",
    "# Layered Architecture (Kurz)\n",
    "- Controller: HTTP, Validierung, Delegation an Service.\n",
    "- Service: Geschäftsregeln, Policies, Transaktionen.\n",
    "- Repository: Persistenz, keine Business-Filter/Mutationen.\n",
    "\"\"\",\n",
    "\"repo_anti_patterns.md\": \"\"\"\n",
    "# Repository Anti-Patterns\n",
    "- Default-Methoden mit .filter/.map: schiebt Logik ins Repository.\n",
    "- Seiteneffekte an Entities im Repo (set*): vermeiden.\n",
    "- Queries mit impliziten Business-Regeln: in Service verschieben.\n",
    "\"\"\",\n",
    "\"spring_layering.md\": \"\"\"\n",
    "# Spring Layering Do/Do not\n",
    "- Controller schlank halten; keine Entscheidungen wie Rabatte/Freigaben.\n",
    "- Entities: keine \"magischen\" Getter mit Berechnung/Seiteneffekt.\n",
    "- Service kapselt Policies (z. B. Rabattberechtigung).\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "RULES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "existing = list(RULES_DIR.glob(\"*.md\"))\n",
    "\n",
    "if not existing:\n",
    "    for name, content in SAMPLE_RULES.items():\n",
    "        (RULES_DIR / name).write_text(textwrap.dedent(content).strip(), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Regeln liegen in:\", RULES_DIR)\n",
    "print(\"Gefundene Dateien:\", [p.name for p in RULES_DIR.glob('*.md')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb3e6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 5 — Utility: grobe Token-Schätzung & Chunking (heading-aware light)\n",
    "def rough_tokens(s: str) -> int:\n",
    "    # sehr grob: 1 Token ~ 0.75 Wörter; hier reicht Wortzählung als Heuristik\n",
    "    return max(1, len(re.findall(r\"\\S+\", s)))\n",
    "\n",
    "def split_by_headings(text: str) -> List[str]:\n",
    "    # einfacher Split bei Markdown-Überschriften\n",
    "    parts = re.split(r\"(?m)^#{1,6}\\s.*$\", text)\n",
    "    parts = [p.strip() for p in parts if p.strip()]\n",
    "    return parts if parts else [text]\n",
    "\n",
    "def sliding_window_chunks(text: str, max_tokens=CHUNK_TOKENS, overlap=OVERLAP_TOKENS) -> List[str]:\n",
    "    words = re.findall(r\"\\S+\", text)\n",
    "    chunks = []\n",
    "    i = 0\n",
    "    step = max(1, max_tokens - overlap)\n",
    "    while i < len(words):\n",
    "        chunk_words = words[i:i+max_tokens]\n",
    "        chunks.append(\" \".join(chunk_words))\n",
    "        i += step\n",
    "    return chunks\n",
    "\n",
    "def chunk_markdown(md_text: str) -> List[str]:\n",
    "    sections = split_by_headings(md_text)\n",
    "    out = []\n",
    "    for sec in sections:\n",
    "        if rough_tokens(sec) <= CHUNK_TOKENS:\n",
    "            out.append(sec)\n",
    "        else:\n",
    "            out.extend(sliding_window_chunks(sec, CHUNK_TOKENS, OVERLAP_TOKENS))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ff06b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 6 — Regeln einlesen & Chunks mit Metadaten erzeugen\n",
    "def load_rules_to_chunks(rules_dir: Path) -> List[Dict[str, Any]]:\n",
    "    all_chunks = []\n",
    "    for md_file in sorted(rules_dir.glob(\"*.md\")):\n",
    "        text = md_file.read_text(encoding=\"utf-8\")\n",
    "        chunks = chunk_markdown(text)\n",
    "        for idx, ch in enumerate(chunks):\n",
    "            all_chunks.append({\n",
    "                \"doc_id\": md_file.name,\n",
    "                \"chunk_id\": idx,\n",
    "                \"text\": ch,\n",
    "            })\n",
    "    return all_chunks\n",
    "\n",
    "chunks = load_rules_to_chunks(RULES_DIR)\n",
    "len(chunks), chunks[0] if chunks else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6854384d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7 — Embedding-Modell laden und Embeddings berechnen\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "def embed_texts(texts: List[str], batch_size=64) -> np.ndarray:\n",
    "    vecs = model.encode(texts, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=True)\n",
    "    return np.asarray(vecs, dtype=\"float32\")\n",
    "\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "embeddings = embed_texts(texts)\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f2fbd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8 — FAISS-Index bauen (cosine sim via dot product mit normalisierten Vektoren)\n",
    "dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dim)  # Inner Product; bei normierten Vektoren = Cosinus\n",
    "index.add(embeddings)\n",
    "print(\"Vektoren im Index:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a119c09c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 9 — Metadaten & Index persistieren\n",
    "faiss.write_index(index, str(INDEX_PATH))\n",
    "with open(META_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for c in chunks:\n",
    "        f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# (Optional) BM25-Korpus persistieren (für Hybrid-Suche)\n",
    "if HAS_BM25:\n",
    "    with open(BM25_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        for c in chunks:\n",
    "            f.write(json.dumps({\"doc_id\": c[\"doc_id\"], \"chunk_id\": c[\"chunk_id\"], \"text\": c[\"text\"]}, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"Gespeichert:\", INDEX_PATH, META_PATH, (\"+ \" + str(BM25_PATH) if HAS_BM25 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ba50ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 10 — Ladefunktionen (Index + Metadaten + optional BM25)\n",
    "def load_index_and_meta():\n",
    "    idx = faiss.read_index(str(INDEX_PATH))\n",
    "    meta = []\n",
    "    with open(META_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            meta.append(json.loads(line))\n",
    "    bm25 = None\n",
    "    if HAS_BM25 and BM25_PATH.exists():\n",
    "        corpus = []\n",
    "        with open(BM25_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                corpus.append(json.loads(line))\n",
    "        bm25 = BM25Okapi([c[\"text\"].split() for c in corpus])\n",
    "        return idx, meta, corpus, bm25\n",
    "    return idx, meta, None, None\n",
    "\n",
    "index, meta, bm25_corpus, bm25 = load_index_and_meta()\n",
    "len(meta), (len(bm25_corpus) if bm25_corpus else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516db29a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11 — Suche: Vektor-only und (optional) Hybrid (BM25 + Vektor mit einfacher Fusion)\n",
    "def vector_search(query: str, k=TOP_K):\n",
    "    qv = embed_texts([query])\n",
    "    scores, ids = index.search(qv, k)\n",
    "    results = []\n",
    "    for score, idx_ in zip(scores[0], ids[0]):\n",
    "        if idx_ == -1:\n",
    "            continue\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"doc_id\": meta[idx_][\"doc_id\"],\n",
    "            \"chunk_id\": meta[idx_][\"chunk_id\"],\n",
    "            \"text\": meta[idx_][\"text\"],\n",
    "            \"rank\": len(results)+1\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def hybrid_search(query: str, k=TOP_K, alpha=0.6):\n",
    "    \"\"\"\n",
    "    alpha ∈ [0,1]: Gewicht für Vektor-Score; (1-alpha) für BM25-Score\n",
    "    Einfache Late-Fusion: normalisierte Scores + Summe\n",
    "    \"\"\"\n",
    "    vec = vector_search(query, k=max(k, 20))  # etwas breiter\n",
    "    if not bm25:\n",
    "        return vec[:k]\n",
    "\n",
    "    tokenized_query = query.split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    # Alle Kandidaten-IDs sammeln\n",
    "    cand_ids = set([ (r[\"doc_id\"], r[\"chunk_id\"]) for r in vec ])\n",
    "    if bm25_corpus:\n",
    "        # nimm die Top-N BM25\n",
    "        top_bm25_idx = np.argsort(bm25_scores)[::-1][:max(k, 50)]\n",
    "        for i in top_bm25_idx:\n",
    "            d = bm25_corpus[i]\n",
    "            cand_ids.add((d[\"doc_id\"], d[\"chunk_id\"]))\n",
    "\n",
    "    # Score-Tabellen aufbauen\n",
    "    v_scores = {}\n",
    "    for r in vec:\n",
    "        v_scores[(r[\"doc_id\"], r[\"chunk_id\"])] = r[\"score\"]\n",
    "    # normieren (0..1)\n",
    "    if v_scores:\n",
    "        v_min, v_max = min(v_scores.values()), max(v_scores.values())\n",
    "        rng = (v_max - v_min) or 1.0\n",
    "        for k_ in v_scores.keys():\n",
    "            v_scores[k_] = (v_scores[k_] - v_min)/rng\n",
    "\n",
    "    b_scores = {}\n",
    "    if bm25_corpus:\n",
    "        for i, s in enumerate(bm25_scores):\n",
    "            d = bm25_corpus[i]\n",
    "            b_scores[(d[\"doc_id\"], d[\"chunk_id\"])] = float(s)\n",
    "        if b_scores:\n",
    "            b_vals = list(b_scores.values())\n",
    "            b_min, b_max = min(b_vals), max(b_vals)\n",
    "            brng = (b_max - b_min) or 1.0\n",
    "            for k_ in b_scores.keys():\n",
    "                b_scores[k_] = (b_scores[k_] - b_min)/brng\n",
    "\n",
    "    fused = []\n",
    "    for key in cand_ids:\n",
    "        vs = v_scores.get(key, 0.0)\n",
    "        bs = b_scores.get(key, 0.0)\n",
    "        fs = alpha*vs + (1-alpha)*bs\n",
    "        d = next(m for m in meta if m[\"doc_id\"]==key[0] and m[\"chunk_id\"]==key[1])\n",
    "        fused.append({\n",
    "            \"score\": float(fs),\n",
    "            \"doc_id\": d[\"doc_id\"],\n",
    "            \"chunk_id\": d[\"chunk_id\"],\n",
    "            \"text\": d[\"text\"]\n",
    "        })\n",
    "    fused.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    for i, r in enumerate(fused):\n",
    "        r[\"rank\"] = i+1\n",
    "    return fused[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07842f9c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 12 — Pretty-Print mit „Zitaten“-Feeling\n",
    "def pretty(results: List[Dict[str, Any]], show_text=True):\n",
    "    for r in results:\n",
    "        header = f\"[{r['rank']}] {r['doc_id']}#chunk-{r['chunk_id']}  score={r['score']:.3f}\"\n",
    "        print(header)\n",
    "        if show_text:\n",
    "            print(textwrap.fill(r[\"text\"], width=100))\n",
    "            print(\"-\"*80)\n",
    "\n",
    "query_examples = [\n",
    "    \"Darf ein Repository Geschäftslogik (Filter/Mutation) enthalten?\",\n",
    "    \"Wo gehört Rabattberechnung laut Layered Architecture hin?\",\n",
    "    \"Welche Aufgaben hat ein Spring Controller und was soll er nicht tun?\"\n",
    "]\n",
    "print(\"Beispiel-Queries:\", query_examples, sep=\"\\n- \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d446d72a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 13 — Demo: Vektor-Suche\n",
    "res = vector_search(query_examples[0], k=TOP_K)\n",
    "pretty(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ebc5e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 14 — Demo: Hybrid-Suche (falls BM25 verfügbar)\n",
    "if bm25:\n",
    "    res_h = hybrid_search(query_examples[1], k=TOP_K, alpha=0.6)\n",
    "    pretty(res_h)\n",
    "else:\n",
    "    print(\"BM25 nicht installiert oder Korpus fehlt — Vektor-Suche genügt für den Workshop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ffb61",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 15 — (Optional) Einfache \"API\" für den späteren Workflow/Agent\n",
    "def retrieve_rules_for_explanation(question: str, k=TOP_K) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Liefert Top-k Passagen (doc_id, chunk_id, text, score) für die Begründung im Report.\n",
    "    \"\"\"\n",
    "    if bm25:\n",
    "        return hybrid_search(question, k=k, alpha=0.6)\n",
    "    return vector_search(question, k=k)\n",
    "\n",
    "# Kurztest\n",
    "test = retrieve_rules_for_explanation(\"Warum ist Business-Logik im Controller problematisch?\", k=3)\n",
    "pretty(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27586ffb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 16 — Mini-Checks (asserts) für den Kurs\n",
    "assert index.ntotal == len(chunks) == embeddings.shape[0] > 0\n",
    "assert INDEX_PATH.exists() and META_PATH.exists()\n",
    "print(\"Smoke-Tests OK ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
