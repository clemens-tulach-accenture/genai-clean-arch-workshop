{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen-AI Workshop: Automatic Detection of Misplaced Business Logic in Java\n",
    "\n",
    "This notebook demonstrates using RAG, Agents, and Workflows to automatically detect Clean Architecture violations in Java code.\n",
    "\n",
    "**Focus:** Identify misplaced business logic (e.g., in controllers, repositories, entities) and explain violations.\n",
    "\n",
    "**Tech Stack:** \n",
    "- Python, OpenAI GPT-4.1-nano\n",
    "- sentence-transformers (embeddings)\n",
    "- FAISS (vector search)\n",
    "- LangChain (agents, workflows)\n",
    "\n",
    "**Workshop Tasks:**\n",
    "1. **Section 1 (RAG):** Implement semantic retrieval function\n",
    "2. **Section 1 (RAG):** Implement RAG analysis function\n",
    "3. **Section 3 (Workflows):** Build deterministic workflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation of dependencies\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: Restart Kernel Now\n",
    "\n",
    "**After running the cell above, you MUST restart the kernel before continuing:**\n",
    "\n",
    "1. Click **Kernel** → **Restart Kernel** in the menu\n",
    "2. Or use keyboard shortcut (typically `0` + `0`)\n",
    "3. Then continue with the cells below\n",
    "\n",
    "This is required for the newly installed packages (especially `mcp`) to be available for import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Install Dependencies\n",
    "\n",
    "**Before running the notebook, install required packages:**\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Installed packages:**\n",
    "- `sentence-transformers` - Text embedding generation\n",
    "- `faiss-cpu` - Fast similarity search\n",
    "- `openai` - OpenAI API client\n",
    "- `langchain` - Agent and workflow framework\n",
    "- `langchain-openai` - OpenAI integration for LangChain\n",
    "- `langchain-community` - Additional LangChain tools\n",
    "- `mcp` - Model Context Protocol\n",
    "\n",
    "**Note:** First execution will download the sentence transformer model (~90MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain, TransformChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the OpenAI API key from the api-key.txt file\n",
    "try:\n",
    "    with open('api-key.txt', 'r') as f:\n",
    "        OPENAI_API_KEY = f.read().strip()\n",
    "    print(\"API key loaded from the api-key.txt file.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\n",
    "        \"Error: 'api-key.txt' not found.\\n\"\n",
    "        \"Please create a file named 'api-key.txt' in the project root directory \"\n",
    "        \"containing the OpenAI API key provided and re-run this cell.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Clean Architecture knowledge base from knowledge-base directory\n",
    "def load_text_file(filepath):\n",
    "    \"\"\"Load text file and return its content.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        return content.replace('\\u200b', '').replace('\\ufeff', '')\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Error: File not found: {filepath}\")\n",
    "\n",
    "# Load all knowledge base markdown files\n",
    "kb_files = [\n",
    "    'knowledge-base/01-layering-principles.md',\n",
    "    'knowledge-base/02-controller-layer.md',\n",
    "    'knowledge-base/03-service-layer.md',\n",
    "    'knowledge-base/04-repository-layer.md',\n",
    "    'knowledge-base/05-entity-layer.md',\n",
    "    'knowledge-base/06-anti-patterns-overview.md'\n",
    "]\n",
    "\n",
    "# Combine all knowledge base files into single corpus\n",
    "KB_MARKDOWN = \"\"\n",
    "for kb_file in kb_files:\n",
    "    content = load_text_file(kb_file)\n",
    "    KB_MARKDOWN += f\"\\n\\n# Source: {kb_file}\\n\\n{content}\"\n",
    "\n",
    "print(\"Knowledge base loaded from:\")\n",
    "for kb_file in kb_files:\n",
    "    print(f\"  - {kb_file}\")\n",
    "print(f\"\\nTotal knowledge base size: {len(KB_MARKDOWN)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load leaky code samples from dummy-project directory\n",
    "LEAKY_SAMPLES = {\n",
    "    \"application\": load_text_file('dummy-project/LeakyDemoApplication.java'),\n",
    "    \"order_entity\": load_text_file('dummy-project/Order.java'),\n",
    "    \"order_controller\": load_text_file('dummy-project/OrderController.java'),\n",
    "    \"order_repository\": load_text_file('dummy-project/OrderRepository.java')\n",
    "}\n",
    "\n",
    "print(\"Leaky code samples loaded from dummy-project:\")\n",
    "for key in LEAKY_SAMPLES.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "print(\"\\nNote: These are intentionally leaky examples for violation detection practice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAG components: Sentence transformer and FAISS index\n",
    "print(\"Initializing RAG components...\")\n",
    "\n",
    "# Load embedding model (downloads on first run)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Sentence transformer model loaded (all-MiniLM-L6-v2)\")\n",
    "\n",
    "# Split knowledge base into chunks (by double newlines = paragraphs)\n",
    "chunks = re.split(r'\\n\\s*\\n', KB_MARKDOWN.strip())\n",
    "print(f\"Knowledge base split into {len(chunks)} chunks\")\n",
    "\n",
    "# Generate embeddings for all chunks\n",
    "embeddings = model.encode(chunks)\n",
    "print(f\"Generated embeddings with dimension {embeddings.shape[1]}\")\n",
    "\n",
    "# Create FAISS index for similarity search\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "print(f\"FAISS index created with {index.ntotal} vectors\")\n",
    "\n",
    "print(\"\\nRAG setup complete. Ready for semantic retrieval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 1: RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "**Goal:** Build a RAG pipeline to retrieve relevant architecture rules and use an LLM to detect violations.\n",
    "\n",
    "**Why RAG?**\n",
    "- Augments LLM with domain-specific Clean Architecture knowledge\n",
    "- Ensures analysis references concrete rules and patterns\n",
    "- Improves accuracy by grounding responses in retrieved context\n",
    "\n",
    "**Workflow:**\n",
    "1. **Retrieve:** Semantic search for relevant rules based on code\n",
    "2. **Augment:** Inject retrieved rules into LLM prompt\n",
    "3. **Generate:** LLM analyzes code against rules, detects violations\n",
    "\n",
    "**Workshop Tasks in this section:**\n",
    "- **Task 1:** Implement `retrieve_relevant_rules()` function\n",
    "- **Task 2:** Implement `analyze_with_rag()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TODO - TASK 1: Implement retrieve_relevant_rules() function\n",
    "# ============================================================================\n",
    "# GOAL: Retrieve the most relevant architecture rule chunks from the knowledge\n",
    "#       base for a given query using semantic similarity search.\n",
    "#\n",
    "# WHAT YOU NEED TO DO:\n",
    "# This function takes a text query (e.g., Java code or a question about\n",
    "# architecture) and finds the most similar chunks in our knowledge base using\n",
    "# vector embeddings and FAISS similarity search.\n",
    "#\n",
    "# Complete the following operations in order:\n",
    "# 1. Convert the query text into a vector embedding using the model\n",
    "# 2. Search the FAISS index to find the indices of the most similar chunks\n",
    "# 3. Retrieve the actual text chunks using those indices\n",
    "# 4. Combine the chunks into a single string and clean up formatting\n",
    "#\n",
    "# AVAILABLE VARIABLES:\n",
    "# - model: SentenceTransformer model for creating embeddings\n",
    "# - index: FAISS index containing all knowledge base embeddings\n",
    "# - chunks: List of text chunks from the knowledge base\n",
    "# - query: The input text to search for (function parameter)\n",
    "# - top_k: Number of chunks to retrieve (function parameter, default=3)\n",
    "# ============================================================================\n",
    "\n",
    "def retrieve_relevant_rules(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Core retrieval function: Embed query, fetch top-k relevant chunks from knowledge base.\n",
    "    \n",
    "    Args:\n",
    "        query (str): Input query (typically Java code or architectural question)\n",
    "        top_k (int): Number of relevant chunks to retrieve (default: 3)\n",
    "        \n",
    "    Returns:\n",
    "        str: Concatenated relevant rule chunks from knowledge base\n",
    "    \"\"\"\n",
    "    # TODO: Encode the query into an embedding vector\n",
    "    # Use: model.encode([query]) - note that query must be in a list\n",
    "    query_embedding = None  # Replace with your code\n",
    "    \n",
    "    # TODO: Search the FAISS index for the most similar chunks\n",
    "    # Use: index.search(np.array(query_embedding), top_k)\n",
    "    # This returns two values: distances and indices. We only need indices.\n",
    "    distances, indices = None, None  # Replace with your code\n",
    "    \n",
    "    # TODO: Extract the text chunks using the indices\n",
    "    # Use: indices[0] to get the array of indices for our query\n",
    "    # Then use a list comprehension to get chunks: [chunks[i] for i in indices[0]]\n",
    "    retrieved_chunks = []  # Replace with your code\n",
    "    \n",
    "    # TODO: Join all chunks with double newlines and clean unicode artifacts\n",
    "    # Use: \"\\n\\n\".join(retrieved_chunks)\n",
    "    # Then use: .replace('\\u200b', '').replace('\\ufeff', '')\n",
    "    relevant = \"\"  # Replace with your code\n",
    "    \n",
    "    return relevant\n",
    "\n",
    "print(\"retrieve_relevant_rules() function defined (implementation required)\")\n",
    "print(\"Complete the TODO comments above to implement semantic retrieval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 1 TEST: Verify retrieve_relevant_rules() implementation\n",
    "# ============================================================================\n",
    "# This test validates your implementation without requiring network access.\n",
    "# It uses the actual model, index, and chunks from the notebook.\n",
    "# ============================================================================\n",
    "\n",
    "def test_retrieve_relevant_rules():\n",
    "    \"\"\"Test the retrieve_relevant_rules implementation.\"\"\"\n",
    "    print(\"Testing retrieve_relevant_rules()...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Test with a sample query\n",
    "    test_query = \"business logic in repository layer\"\n",
    "    print(f\"Query: '{test_query}'\")\n",
    "    \n",
    "    try:\n",
    "        result = retrieve_relevant_rules(test_query, top_k=3)\n",
    "        \n",
    "        # Validate result\n",
    "        assert isinstance(result, str), \"Result must be a string\"\n",
    "        assert len(result) > 0, \"Result must not be empty\"\n",
    "        assert \"\\n\\n\" in result or len(result.split()) > 10, \"Result should contain retrieved content\"\n",
    "        \n",
    "        # Check no unicode artifacts\n",
    "        assert '\\u200b' not in result, \"Unicode artifacts should be removed\"\n",
    "        assert '\\ufeff' not in result, \"Unicode artifacts should be removed\"\n",
    "        \n",
    "        print(f\"✓ Retrieved {len(result)} characters\")\n",
    "        print(f\"✓ Content preview: {result[:200]}...\")\n",
    "        print(\"\\n✓ All tests passed!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Test failed: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_retrieve_relevant_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TODO - TASK 2: Implement analyze_with_rag() function\n",
    "# ============================================================================\n",
    "# GOAL: Use OpenAI's LLM to analyze Java code for Clean Architecture violations\n",
    "#       using retrieved architecture rules as context (Retrieval-Augmented Generation).\n",
    "#\n",
    "# WHAT YOU NEED TO DO:\n",
    "# This function takes Java source code and relevant architecture rules, then\n",
    "# sends them to the OpenAI API for analysis. The LLM will identify violations\n",
    "# based on the provided rules.\n",
    "#\n",
    "# Complete the following operations in order:\n",
    "# 1. Create an OpenAI client instance for API communication\n",
    "# 2. Define the system message that sets the LLM's role and behavior\n",
    "# 3. Build the user message containing the code, rules, and analysis instructions\n",
    "# 4. Send both messages to OpenAI's chat completion API\n",
    "# 5. Extract and return the analysis text from the API response\n",
    "#\n",
    "# AVAILABLE VARIABLES:\n",
    "# - OPENAI_API_KEY: Your OpenAI API key (already loaded)\n",
    "# - java_code: The Java source code to analyze (function parameter)\n",
    "# - rules: The retrieved architecture rules (function parameter)\n",
    "#\n",
    "# API STRUCTURE:\n",
    "# The OpenAI chat API expects:\n",
    "# - model: \"gpt-4.1-nano\"\n",
    "# - messages: List of {\"role\": \"system\" or \"user\", \"content\": \"text\"} dicts\n",
    "# Response structure: response.choices[0].message.content\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_with_rag(java_code: str, rules: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze Java code using RAG (Retrieval-Augmented Generation).\n",
    "    \n",
    "    Args:\n",
    "        java_code (str): Java source code to analyze\n",
    "        rules (str): Retrieved architecture rules for context\n",
    "        \n",
    "    Returns:\n",
    "        str: Analysis report identifying violations and recommendations\n",
    "    \"\"\"\n",
    "    # TODO: Create OpenAI client instance\n",
    "    # Use: OpenAI(api_key=OPENAI_API_KEY)\n",
    "    client = None  # Replace with your code\n",
    "    \n",
    "    # TODO: Define the system message\n",
    "    # This tells the LLM its role: a Java architecture expert specializing\n",
    "    # in Clean Architecture who analyzes code for misplaced business logic\n",
    "    system_message = \"\"  # Replace with your code\n",
    "    \n",
    "    # TODO: Build the user message\n",
    "    # Include: the Java code, the rules, and detailed instructions for analysis\n",
    "    # Format each violation with: location, type, reasoning, impact, fix\n",
    "    user_message = \"\"  # Replace with your code\n",
    "    \n",
    "    # TODO: Call the OpenAI API\n",
    "    # Use: client.chat.completions.create()\n",
    "    # Pass: model=\"gpt-4.1-nano\" and messages list\n",
    "    response = None  # Replace with your code\n",
    "    \n",
    "    # TODO: Extract the analysis text from the response\n",
    "    # Use: response.choices[0].message.content\n",
    "    analysis = \"\"  # Replace with your code\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "print(\"analyze_with_rag() function defined (implementation required)\")\n",
    "print(\"Complete the TODO comments above to implement RAG analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 2 TEST: Verify analyze_with_rag() implementation\n",
    "# ============================================================================\n",
    "# This test validates your implementation without actually calling OpenAI.\n",
    "# It uses a monkey-patched mock to verify the function structure.\n",
    "# ============================================================================\n",
    "\n",
    "def test_analyze_with_rag():\n",
    "    \"\"\"Test the analyze_with_rag implementation with a mock.\"\"\"\n",
    "    print(\"Testing analyze_with_rag()...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Create mock response\n",
    "    class MockChoice:\n",
    "        class MockMessage:\n",
    "            content = \"Mock analysis: Found business logic in controller at line 15.\"\n",
    "        message = MockMessage()\n",
    "    \n",
    "    class MockResponse:\n",
    "        choices = [MockChoice()]\n",
    "    \n",
    "    # Monkey patch OpenAI\n",
    "    import sys\n",
    "    original_openai = sys.modules.get('openai')\n",
    "    \n",
    "    class MockOpenAI:\n",
    "        def __init__(self, api_key=None):\n",
    "            self.api_key = api_key\n",
    "            \n",
    "        class chat:\n",
    "            class completions:\n",
    "                @staticmethod\n",
    "                def create(**kwargs):\n",
    "                    return MockResponse()\n",
    "    \n",
    "    try:\n",
    "        # Temporarily replace OpenAI\n",
    "        sys.modules['openai'] = type(sys)('openai')\n",
    "        sys.modules['openai'].OpenAI = MockOpenAI\n",
    "        from openai import OpenAI as TestOpenAI\n",
    "        \n",
    "        # Reload function with mock\n",
    "        test_code = \"public class Test { void method() { /* logic */ } }\"\n",
    "        test_rules = \"Controllers should not contain business logic.\"\n",
    "        \n",
    "        # Test with mock\n",
    "        global OpenAI\n",
    "        OpenAI_backup = OpenAI\n",
    "        OpenAI = TestOpenAI\n",
    "        \n",
    "        result = analyze_with_rag(test_code, test_rules)\n",
    "        \n",
    "        # Validate result\n",
    "        assert isinstance(result, str), \"Result must be a string\"\n",
    "        assert len(result) > 0, \"Result must not be empty\"\n",
    "        \n",
    "        print(f\"✓ Function executed successfully\")\n",
    "        print(f\"✓ Result type: {type(result).__name__}\")\n",
    "        print(f\"✓ Result length: {len(result)} characters\")\n",
    "        print(\"\\n✓ All tests passed!\")\n",
    "        \n",
    "        # Restore\n",
    "        OpenAI = OpenAI_backup\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Test failed: {str(e)}\")\n",
    "        return False\n",
    "    finally:\n",
    "        # Restore original openai module\n",
    "        if original_openai:\n",
    "            sys.modules['openai'] = original_openai\n",
    "\n",
    "# Run the test\n",
    "test_analyze_with_rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RAG Pipeline Demo: Using the implemented functions\n",
    "# ============================================================================\n",
    "# This cell demonstrates the complete RAG pipeline using your implementations.\n",
    "# ============================================================================\n",
    "\n",
    "# Select sample for RAG analysis\n",
    "sample_name = \"order_controller\"\n",
    "java_code = LEAKY_SAMPLES[sample_name]\n",
    "\n",
    "print(f\"Analyzing: {sample_name} (leaky code from dummy-project)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Code snippet (first 600 chars):\")\n",
    "print(java_code[:600], \"...\\n\")\n",
    "\n",
    "# Step 1: Retrieve relevant architecture rules\n",
    "print(\"Step 1: Retrieving relevant rules...\")\n",
    "relevant_rules = retrieve_relevant_rules(java_code)\n",
    "print(f\"Retrieved {len(relevant_rules)} characters of rules\\n\")\n",
    "\n",
    "# Step 2: Analyze with RAG\n",
    "print(\"Step 2: Analyzing with RAG...\")\n",
    "analysis = analyze_with_rag(java_code, relevant_rules)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RAG Analysis Result:\")\n",
    "print(\"=\" * 70)\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for File Generation\n",
    "\n",
    "These functions are used throughout the notebook to:\n",
    "1. Prepare output directories for fixed code\n",
    "2. Infer Java filenames from class definitions\n",
    "3. Generate corrected Java code using LLM with architecture rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: prepare fixed directory, infer Java filename, create corrected Java via LLM\n",
    "import pathlib\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def prepare_fixed_dir(path: str = 'dummy-project/fixed'):\n",
    "    \"\"\"\n",
    "    Prepare output directory for fixed Java files.\n",
    "    Creates directory if it doesn't exist, removes existing files if it does.\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to the fixed files directory\n",
    "        \n",
    "    Returns:\n",
    "        pathlib.Path: Path object for the prepared directory\n",
    "    \"\"\"\n",
    "    d = pathlib.Path(path)\n",
    "    if d.exists():\n",
    "        shutil.rmtree(d)\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d\n",
    "\n",
    "def infer_java_filename(code: str, fallback: str) -> str:\n",
    "    \"\"\"\n",
    "    Infer Java filename from code by finding the primary type name.\n",
    "    Looks for class, interface, or enum declarations.\n",
    "    \n",
    "    Args:\n",
    "        code (str): Java source code\n",
    "        fallback (str): Fallback filename if no type declaration found\n",
    "        \n",
    "    Returns:\n",
    "        str: Inferred filename (e.g., \"OrderController.java\")\n",
    "    \"\"\"\n",
    "    m = re.search(r'\\b(class|interface|enum)\\s+([A-Z][A-Za-z0-9_]*)', code)\n",
    "    if m:\n",
    "        return f\"{m.group(2)}.java\"\n",
    "    return fallback\n",
    "\n",
    "def make_fixed_java(filename: str, code: str, rules: str, model: str = 'gpt-4.1-nano') -> str:\n",
    "    \"\"\"\n",
    "    Generate corrected Java code using LLM with architecture rules as context.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Java filename to determine layer-specific refactoring hints\n",
    "        code (str): Original Java source code with violations\n",
    "        rules (str): Relevant architecture rules from knowledge base\n",
    "        model (str): OpenAI model to use (default: gpt-4.1-nano)\n",
    "        \n",
    "    Returns:\n",
    "        str: Corrected Java source code\n",
    "    \"\"\"\n",
    "    role = ('controller' if filename.lower().endswith('controller.java') else\n",
    "            'repository' if filename.lower().endswith('repository.java') else\n",
    "            'entity' if filename.lower().endswith('order.java') else 'java')\n",
    "    system = (\n",
    "        'You are a senior Java/Spring reviewer. Refactor the given file to comply with Clean Architecture.\\n'\n",
    "        f'Keep the same package and imports. Remove misplaced business logic from the {role}.\\n'\n",
    "        'Controllers: only HTTP mapping, DTO mapping, delegate to OrderService.\\n'\n",
    "        'Repositories: only persistence interfaces/CRUD, no domain computations.\\n'\n",
    "        'Entities: plain domain with fields/getters/setters, no I/O or service/repo calls.\\n'\n",
    "        'If delegation is needed, call an OrderService (assume it exists); do not inline logic.\\n'\n",
    "        'Return ONLY the corrected Java file content.'\n",
    "    )\n",
    "    user = (\n",
    "        f'Relevant architecture rules:\\n{rules}\\n\\n'\n",
    "        f'File name: {filename}\\n\\n'\n",
    "        f'Original Java file:\\n{code}\\n'\n",
    "    )\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    rsp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
    "    )\n",
    "    return rsp.choices[0].message.content\n",
    "\n",
    "print(\"Helper functions defined:\")\n",
    "print(\"  - prepare_fixed_dir(): Prepare output directory\")\n",
    "print(\"  - infer_java_filename(): Extract filename from code\")\n",
    "print(\"  - make_fixed_java(): Generate corrected code via LLM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 2: Agents (ReAct Framework)\n",
    "\n",
    "**Goal:** Create an autonomous agent that reasons about when to retrieve rules and how to analyze code step-by-step.\n",
    "\n",
    "**Why Agents?**\n",
    "- **Autonomy:** Agent decides if/when to use the retrieval tool\n",
    "- **Reasoning:** Breaks down complex analysis into logical steps\n",
    "- **Flexibility:** Handles multi-file or contextual analysis\n",
    "\n",
    "**ReAct Pattern:** \n",
    "- **Reason (Thought):** Agent thinks about what to do next\n",
    "- **Act (Action):** Agent uses a tool (e.g., RetrieveArchitectureRules)\n",
    "- **Observe (Observation):** Agent sees tool output\n",
    "- **Repeat:** Continue until reaching final answer\n",
    "\n",
    "**Builds on RAG:** Wraps `retrieve_relevant_rules` as a tool the agent can call autonomously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap retrieval function as an agent tool\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"RetrieveArchitectureRules\",\n",
    "        func=retrieve_relevant_rules,\n",
    "        description=(\n",
    "            \"Retrieve Clean Architecture rules, anti-patterns, and violation examples \"\n",
    "            \"for analyzing Java code. Input should be Java code or a description of \"\n",
    "            \"the architectural concern. Returns relevant rules from the knowledge base.\"\n",
    "        )\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"Agent tools defined:\")\n",
    "for tool in tools:\n",
    "    print(f\"  - Tool: {tool.name}\")\n",
    "    print(f\"    Description: {tool.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TODO - TASK 3 : Initialize a ReAct Agent with Tools\n",
    "# ============================================================================\n",
    "# GOAL: Configure and initialize an autonomous agent that can reason about\n",
    "#       when to use tools and how to analyze code step-by-step.\n",
    "#\n",
    "# WHAT YOU NEED TO DO:\n",
    "# Create a ReAct (Reasoning + Acting) agent that can autonomously decide when\n",
    "# to retrieve architecture rules and how to analyze Java code. The agent will\n",
    "# use the \"thought → action → observation\" loop to solve complex tasks.\n",
    "#\n",
    "# Complete the agent initialization with these components:\n",
    "# 1. Provide the list of available tools (already defined as 'tools')\n",
    "# 2. Provide the language model for reasoning (already created as 'llm')\n",
    "# 3. Set the agent type to ZERO_SHOT_REACT_DESCRIPTION\n",
    "# 4. Enable verbose mode to see the agent's reasoning process\n",
    "# 5. Enable error handling to make the agent robust\n",
    "#\n",
    "# AVAILABLE VARIABLES:\n",
    "# - tools: List containing RetrieveArchitectureRules tool\n",
    "# - llm: ChatOpenAI instance configured with gpt-4.1-nano\n",
    "# - AgentType: Enum with agent type options\n",
    "#\n",
    "# AGENT TYPES:\n",
    "# - ZERO_SHOT_REACT_DESCRIPTION: Agent reasons from tool descriptions only\n",
    "#   (no examples needed, suitable for our use case)\n",
    "#\n",
    "# WHY VERBOSE & ERROR HANDLING:\n",
    "# - verbose=True: Shows the agent's thinking process (Thought/Action/Observation)\n",
    "# - handle_parsing_errors=True: Agent recovers from malformed tool calls\n",
    "# ============================================================================\n",
    "\n",
    "# Create LLM instance for the agent\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "# TODO: Initialize the ReAct agent with proper configuration\n",
    "# Use: initialize_agent(tools=..., llm=..., agent=..., verbose=..., handle_parsing_errors=...)\n",
    "agent = None  # Replace with your code\n",
    "\n",
    "print(\"Agent initialization status:\", \"✓ Complete\" if agent else \"✗ Incomplete\")\n",
    "if agent:\n",
    "    print(\"  - Agent type: ZERO_SHOT_REACT_DESCRIPTION\")\n",
    "    print(\"  - Verbose mode: Enabled\")\n",
    "    print(\"  - Error handling: Enabled\")\n",
    "    print(\"\\nAgent ready to reason and act autonomously\")\n",
    "else:\n",
    "    print(\"Complete the TODO above to initialize the agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 3 TEST: Verify agent initialization\n",
    "# ============================================================================\n",
    "# This test validates that the agent is properly configured.\n",
    "# It checks the agent's configuration without running any analysis.\n",
    "# ============================================================================\n",
    "\n",
    "def test_agent_initialization():\n",
    "    \"\"\"Test the agent initialization and configuration.\"\"\"\n",
    "    print(\"Testing agent initialization...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Check that agent exists\n",
    "        assert agent is not None, \"Agent must be initialized\"\n",
    "        \n",
    "        # Check agent has tools\n",
    "        assert hasattr(agent, 'tools'), \"Agent must have tools attribute\"\n",
    "        assert len(agent.tools) > 0, \"Agent must have at least one tool\"\n",
    "        \n",
    "        # Check tool is correct\n",
    "        tool_names = [tool.name for tool in agent.tools]\n",
    "        assert \"RetrieveArchitectureRules\" in tool_names, \\\n",
    "            \"Agent must have RetrieveArchitectureRules tool\"\n",
    "        \n",
    "        # Check agent configuration\n",
    "        assert hasattr(agent, 'agent'), \"Agent must have agent executor\"\n",
    "        \n",
    "        # Check verbose mode (if accessible)\n",
    "        if hasattr(agent, 'verbose'):\n",
    "            assert agent.verbose == True, \"Verbose mode should be enabled\"\n",
    "        \n",
    "        print(\"✓ Agent is initialized\")\n",
    "        print(\"✓ Agent has correct tools\")\n",
    "        print(f\"✓ Available tools: {', '.join(tool_names)}\")\n",
    "        print(\"✓ Agent configuration is correct\")\n",
    "        print(\"\\n✓ All tests passed!\")\n",
    "        print(\"\\nAgent is ready to use. Try running it with a code analysis task.\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"✗ Test failed: {str(e)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_agent_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select sample for agent analysis\n",
    "agent_sample_name = \"order_repository\"\n",
    "agent_code = LEAKY_SAMPLES[agent_sample_name]\n",
    "\n",
    "# Craft prompt to encourage tool use and step-by-step reasoning\n",
    "agent_prompt = (\n",
    "    f\"Analyze the following Java repository interface for Clean Architecture violations. \"\n",
    "    f\"First, use the RetrieveArchitectureRules tool to get relevant rules about repositories. \"\n",
    "    f\"Then, identify all violations step-by-step.\\n\\n\"\n",
    "    f\"Java Code:\\n{agent_code}\"\n",
    ")\n",
    "\n",
    "print(f\"Running agent analysis on: {agent_sample_name}\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Watch the agent's reasoning process below:\\n\")\n",
    "\n",
    "result = agent.run(agent_prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Agent's Final Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate agent handling multiple file context\n",
    "print(\"Agent Analysis: Multiple Files from dummy-project\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "multi_file_prompt = (\n",
    "    f\"I have a Spring Boot application with potential architecture violations. \"\n",
    "    f\"Analyze these three files and identify which layers are violating Clean Architecture:\\n\\n\"\n",
    "    f\"1. Order Controller:\\n{LEAKY_SAMPLES['order_controller']}\\n\\n\"\n",
    "    f\"2. Order Repository:\\n{LEAKY_SAMPLES['order_repository']}\\n\\n\"\n",
    "    f\"3. Order Entity:\\n{LEAKY_SAMPLES['order_entity']}\\n\\n\"\n",
    "    f\"For each file, identify violations and explain their impact on maintainability.\"\n",
    ")\n",
    "\n",
    "print(\"Agent will analyze all three files...\\n\")\n",
    "multi_result = agent.run(multi_file_prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Multi-File Analysis Result:\")\n",
    "print(\"=\" * 70)\n",
    "print(multi_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 3: Workflows (Deterministic Pipelines)\n",
    "\n",
    "**Goal:** Orchestrate a fixed, predictable sequence of steps: Retrieve → Analyze → Output.\n",
    "\n",
    "**Why Workflows?**\n",
    "- **Deterministic:** Same input always produces same sequence of operations\n",
    "- **Production-ready:** Suitable for CI/CD integration\n",
    "- **Debuggable:** Easy to trace execution with verbose logging\n",
    "- **Consistent:** Every code sample analyzed the same way\n",
    "\n",
    "**Workflow Steps:**\n",
    "1. **TransformChain (Retrieval):** Fetch relevant rules based on input code\n",
    "2. **LLMChain (Analysis):** Analyze code with retrieved rules, generate violation report\n",
    "\n",
    "**Workshop Task in this section:**\n",
    "- **Task 3:** Implement workflow transform function and chain composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM for workflow chains\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", api_key=OPENAI_API_KEY)\n",
    "print(\"LLM initialized for workflow chains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TODO - TASK 4: Implement transform_retrieval() function\n",
    "# ============================================================================\n",
    "# GOAL: Create a transform function that wraps the retrieval logic for use\n",
    "#       in a LangChain workflow pipeline (SequentialChain).\n",
    "#\n",
    "# WHAT YOU NEED TO DO:\n",
    "# This function is a wrapper that adapts our retrieve_relevant_rules() function\n",
    "# to work within LangChain's workflow system. Workflows pass data between steps\n",
    "# using dictionaries, so we need to:\n",
    "# - Extract inputs from a dictionary\n",
    "# - Call our retrieval function\n",
    "# - Return outputs in a dictionary format\n",
    "#\n",
    "# The function receives a dictionary with \"code\" key and must return a\n",
    "# dictionary with \"rules\" key. This allows the workflow to chain multiple\n",
    "# steps together, passing data from one to the next.\n",
    "#\n",
    "# Complete these operations:\n",
    "# 1. Extract the code string from the inputs dictionary\n",
    "# 2. Use the retrieve_relevant_rules() function to get architecture rules\n",
    "# 3. Return a dictionary containing the rules (key must be \"rules\")\n",
    "#\n",
    "# IMPORTANT:\n",
    "# - Return ONLY {\"rules\": ...} - no other keys!\n",
    "# - The output key \"rules\" must match what the next chain expects as input\n",
    "# - This is a \"transform\" function - it transforms inputs to outputs\n",
    "#\n",
    "# AVAILABLE VARIABLES:\n",
    "# - inputs: Dictionary parameter containing {\"code\": \"...\"}\n",
    "# - retrieve_relevant_rules: Function from Task 1 (already implemented)\n",
    "# ============================================================================\n",
    "\n",
    "def transform_retrieval(inputs):\n",
    "    \"\"\"\n",
    "    Transform function for retrieval chain.\n",
    "    Takes code as input, retrieves relevant rules from knowledge base.\n",
    "    Note: Returns only 'rules' to avoid key duplication in SequentialChain.\n",
    "    \n",
    "    Args:\n",
    "        inputs (dict): Dictionary with \"code\" key containing Java source code\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with \"rules\" key containing retrieved architecture rules\n",
    "    \"\"\"\n",
    "    # TODO: Extract the code from inputs dictionary\n",
    "    # The key is \"code\"\n",
    "    code = None  # Replace with your code\n",
    "    \n",
    "    # TODO: Call retrieve_relevant_rules() to get relevant rules for this code\n",
    "    rules = None  # Replace with your code\n",
    "    \n",
    "    # TODO: Return a dictionary with \"rules\" as the key\n",
    "    # The value should be the rules string you just retrieved\n",
    "    return {}  # Replace with your code\n",
    "\n",
    "# Create the TransformChain using your function\n",
    "retrieval_chain = TransformChain(\n",
    "    input_variables=[\"code\"],\n",
    "    output_variables=[\"rules\"],\n",
    "    transform=transform_retrieval\n",
    ")\n",
    "\n",
    "print(\"transform_retrieval() function defined (implementation required)\")\n",
    "print(\"Complete the TODO comments above to enable workflow retrieval step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 4 TEST: Verify transform_retrieval() implementation\n",
    "# ============================================================================\n",
    "# This test validates the transform function without requiring network access.\n",
    "# It checks the function structure and data flow.\n",
    "# ============================================================================\n",
    "\n",
    "def test_transform_retrieval():\n",
    "    \"\"\"Test the transform_retrieval implementation.\"\"\"\n",
    "    print(\"Testing transform_retrieval()...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Test with sample input\n",
    "        test_input = {\"code\": \"public class Test { void method() {} }\"}\n",
    "        \n",
    "        # Call the function directly\n",
    "        result = transform_retrieval(test_input)\n",
    "        \n",
    "        # Validate result structure\n",
    "        assert isinstance(result, dict), \"Result must be a dictionary\"\n",
    "        assert \"rules\" in result, \"Result must contain 'rules' key\"\n",
    "        assert isinstance(result[\"rules\"], str), \"Rules must be a string\"\n",
    "        assert len(result) == 1, \"Result must contain ONLY 'rules' key (no other keys)\"\n",
    "        \n",
    "        # Validate content\n",
    "        assert len(result[\"rules\"]) > 0, \"Rules must not be empty\"\n",
    "        \n",
    "        # Validate chain configuration\n",
    "        assert hasattr(retrieval_chain, 'input_variables'), \\\n",
    "            \"Chain must have input_variables attribute\"\n",
    "        assert hasattr(retrieval_chain, 'output_variables'), \\\n",
    "            \"Chain must have output_variables attribute\"\n",
    "        assert retrieval_chain.input_variables == [\"code\"], \\\n",
    "            \"Chain input variables must be ['code']\"\n",
    "        assert retrieval_chain.output_variables == [\"rules\"], \\\n",
    "            \"Chain output variables must be ['rules']\"\n",
    "        \n",
    "        # Validate the chain is a TransformChain\n",
    "        assert isinstance(retrieval_chain, TransformChain), \\\n",
    "            \"Chain must be a TransformChain instance\"\n",
    "        \n",
    "        print(\"✓ Function accepts dictionary input correctly\")\n",
    "        print(\"✓ Function returns dictionary with 'rules' key\")\n",
    "        print(\"✓ Function returns only one key (no duplication)\")\n",
    "        print(f\"✓ Retrieved {len(result['rules'])} characters of rules\")\n",
    "        print(\"✓ TransformChain is properly configured\")\n",
    "        print(\"✓ Chain has correct input/output variables\")\n",
    "        print(\"\\n✓ All tests passed!\")\n",
    "        print(\"\\nThe retrieval step is ready for workflow integration.\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"✗ Test failed: {str(e)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_transform_retrieval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 2: Analysis step - LLM analyzes code with retrieved rules\n",
    "analysis_prompt = PromptTemplate.from_template(\n",
    "    \"You are a Java architecture expert analyzing code for Clean Architecture violations.\\n\\n\"\n",
    "    \"Java Code:\\n{code}\\n\\n\"\n",
    "    \"Relevant Architecture Rules:\\n{rules}\\n\\n\"\n",
    "    \"Task:\\n\"\n",
    "    \"1. List all violations with exact locations (class, method, line)\\n\"\n",
    "    \"2. Explain why each violates Clean Architecture principles\\n\"\n",
    "    \"3. Cite specific rules from the provided architecture rules\\n\"\n",
    "    \"4. Describe impact on maintainability, testability, and scalability\\n\"\n",
    "    \"5. Provide refactoring recommendations (which layer should contain the logic)\\n\\n\"\n",
    "    \"Format your analysis clearly with numbered sections for each violation.\"\n",
    ")\n",
    "\n",
    "analysis_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=analysis_prompt,\n",
    "    output_key=\"analysis\"\n",
    ")\n",
    "\n",
    "print(\"Analysis chain created (LLMChain)\")\n",
    "print(\"  - Input: code, rules\")\n",
    "print(\"  - Output: analysis\")\n",
    "print(\"  - Prompt: Structured violation analysis with citations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TODO - TASK 5: Compose a complete SequentialChain workflow\n",
    "# ============================================================================\n",
    "# GOAL: Wire together the retrieval and analysis chains into a deterministic,\n",
    "#       production-ready workflow pipeline.\n",
    "#\n",
    "# WHAT YOU NEED TO DO:\n",
    "# Create a SequentialChain that executes multiple steps in a fixed order:\n",
    "# 1. Retrieval step (TransformChain): Code → Rules\n",
    "# 2. Analysis step (LLMChain): Code + Rules → Analysis\n",
    "#\n",
    "# This creates a deterministic workflow where the same input always produces\n",
    "# the same sequence of operations. This is ideal for CI/CD pipelines, batch\n",
    "# processing, and production systems where predictability is crucial.\n",
    "#\n",
    "# Configure the workflow with:\n",
    "# 1. The list of chains to execute (in order!)\n",
    "# 2. The input variables the workflow accepts from the user\n",
    "# 3. The output variables the workflow returns to the user\n",
    "# 4. Verbose mode to see execution logs (for debugging)\n",
    "#\n",
    "# DATA FLOW:\n",
    "# User provides: {\"code\": \"...\"}\n",
    "# After Step 1 (retrieval_chain): {\"code\": \"...\", \"rules\": \"...\"}\n",
    "# After Step 2 (analysis_chain): {\"code\": \"...\", \"rules\": \"...\", \"analysis\": \"...\"}\n",
    "# User receives: {\"analysis\": \"...\"}\n",
    "#\n",
    "# AVAILABLE VARIABLES:\n",
    "# - retrieval_chain: TransformChain (already created with your function)\n",
    "# - analysis_chain: LLMChain (already created, uses OpenAI for analysis)\n",
    "# ============================================================================\n",
    "\n",
    "# Compose full workflow: Retrieval → Analysis\n",
    "workflow = SequentialChain(\n",
    "    # TODO: Specify the chains in execution order\n",
    "    # First: retrieval_chain (gets rules)\n",
    "    # Second: analysis_chain (analyzes code with rules)\n",
    "    chains=None,  # Replace with your code\n",
    "    \n",
    "    # TODO: Define what inputs the workflow accepts\n",
    "    # The workflow needs \"code\" from the user\n",
    "    input_variables=None,  # Replace with your code\n",
    "    \n",
    "    # TODO: Define what outputs the workflow returns\n",
    "    # The workflow returns \"analysis\" to the user\n",
    "    output_variables=None,  # Replace with your code\n",
    "    \n",
    "    # TODO: Enable verbose mode to see step-by-step execution\n",
    "    verbose=None  # Replace with your code\n",
    ")\n",
    "\n",
    "print(\"Workflow composition status:\", \"✓ Complete\" if workflow else \"✗ Incomplete\")\n",
    "if workflow and hasattr(workflow, 'chains'):\n",
    "    print(f\"  - Number of chains: {len(workflow.chains)}\")\n",
    "    print(f\"  - Input variables: {workflow.input_variables}\")\n",
    "    print(f\"  - Output variables: {workflow.output_variables}\")\n",
    "    print(\"\\nWorkflow ready for execution\")\n",
    "else:\n",
    "    print(\"Complete the TODO above to compose the workflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TASK 5 TEST: Verify SequentialChain workflow composition\n",
    "# ============================================================================\n",
    "# This test validates the workflow structure and configuration.\n",
    "# It checks chain composition and data flow without executing the workflow.\n",
    "# ============================================================================\n",
    "\n",
    "def test_workflow_composition():\n",
    "    \"\"\"Test the workflow composition and configuration.\"\"\"\n",
    "    print(\"Testing workflow composition...\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        # Check workflow exists and is correct type\n",
    "        assert workflow is not None, \"Workflow must be initialized\"\n",
    "        assert isinstance(workflow, SequentialChain), \\\n",
    "            \"Workflow must be a SequentialChain\"\n",
    "        \n",
    "        # Check chains configuration\n",
    "        assert hasattr(workflow, 'chains'), \"Workflow must have 'chains' attribute\"\n",
    "        assert len(workflow.chains) == 2, \\\n",
    "            \"Workflow must have exactly 2 chains (retrieval + analysis)\"\n",
    "        \n",
    "        # Check chain order and types\n",
    "        assert isinstance(workflow.chains[0], TransformChain), \\\n",
    "            \"First chain must be TransformChain (retrieval)\"\n",
    "        assert isinstance(workflow.chains[1], LLMChain), \\\n",
    "            \"Second chain must be LLMChain (analysis)\"\n",
    "        \n",
    "        # Check input/output variables\n",
    "        assert workflow.input_variables == [\"code\"], \\\n",
    "            \"Workflow input must be ['code']\"\n",
    "        assert workflow.output_variables == [\"analysis\"], \\\n",
    "            \"Workflow output must be ['analysis']\"\n",
    "        \n",
    "        # Check verbose mode\n",
    "        assert workflow.verbose == True, \\\n",
    "            \"Verbose mode should be enabled for debugging\"\n",
    "        \n",
    "        # Validate data flow compatibility\n",
    "        # Step 1: retrieval_chain\n",
    "        assert workflow.chains[0].input_variables == [\"code\"], \\\n",
    "            \"Retrieval chain must accept 'code' input\"\n",
    "        assert workflow.chains[0].output_variables == [\"rules\"], \\\n",
    "            \"Retrieval chain must output 'rules'\"\n",
    "        \n",
    "        # Step 2: analysis_chain\n",
    "        assert workflow.chains[1].output_key == \"analysis\", \\\n",
    "            \"Analysis chain must output 'analysis'\"\n",
    "        \n",
    "        print(\"✓ Workflow is initialized correctly\")\n",
    "        print(\"✓ Workflow has 2 chains in correct order\")\n",
    "        print(\"✓ Chain 1: TransformChain (retrieval)\")\n",
    "        print(\"✓ Chain 2: LLMChain (analysis)\")\n",
    "        print(\"✓ Input variables: ['code']\")\n",
    "        print(\"✓ Output variables: ['analysis']\")\n",
    "        print(\"✓ Verbose mode: Enabled\")\n",
    "        print(\"✓ Data flow is properly wired\")\n",
    "        print(\"\\n✓ All tests passed!\")\n",
    "        print(\"\\nWorkflow is ready to process Java code:\")\n",
    "        print(\"  Input:  {'code': '...'}\")\n",
    "        print(\"  Output: {'analysis': '...'}\")\n",
    "        return True\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        print(f\"✗ Test failed: {str(e)}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Unexpected error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Run the test\n",
    "test_workflow_composition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute workflow on leaky controller\n",
    "workflow_sample_name = \"order_controller\"\n",
    "workflow_code = LEAKY_SAMPLES[workflow_sample_name]\n",
    "\n",
    "print(f\"Executing workflow on: {workflow_sample_name} (leaky code)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "result = workflow({\"code\": workflow_code})\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Workflow Output:\")\n",
    "print(\"=\" * 70)\n",
    "print(result[\"analysis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run workflow on all leaky samples for comprehensive analysis\n",
    "print(\"Batch Workflow Execution: All Leaky Samples from dummy-project\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "batch_results = {}\n",
    "\n",
    "for sample_name, code in LEAKY_SAMPLES.items():\n",
    "    if sample_name == \"application\":\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nAnalyzing: {sample_name}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    try:\n",
    "        result = workflow({\"code\": code})\n",
    "        batch_results[sample_name] = result[\"analysis\"]\n",
    "        print(f\"Analysis complete for {sample_name}\")\n",
    "        print(\"Summary (first 400 chars):\")\n",
    "        print(result[\"analysis\"][:400], \"...\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {sample_name}: {str(e)}\")\n",
    "        batch_results[sample_name] = f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Batch Execution Complete\")\n",
    "print(f\"Successfully analyzed {len(batch_results)} files\")\n",
    "print(\"\\nAll results stored in batch_results dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Section 4: Generate Corrected Java Files\n",
    "\n",
    "This section takes the analyzed leaky code samples and generates corrected versions that comply with Clean Architecture principles.\n",
    "\n",
    "**Output:** Corrected Java files written to `dummy-project/fixed/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output directory dummy-project/fixed (create or clean)\n",
    "fixed_dir = prepare_fixed_dir('dummy-project/fixed')\n",
    "print(f\"Prepared fixed directory: {fixed_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fixed versions for all leaky files and write them to dummy-project/fixed\n",
    "generated_paths = []\n",
    "\n",
    "filename_map = {\n",
    "    'application': 'LeakyDemoApplication.java',\n",
    "    'order_controller': 'OrderController.java',\n",
    "    'order_repository': 'OrderRepository.java',\n",
    "    'order_entity': 'Order.java'\n",
    "}\n",
    "\n",
    "print(\"Generating corrected Java files...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, code in LEAKY_SAMPLES.items():\n",
    "    src_filename = filename_map.get(name, f\"{name}.java\")\n",
    "    print(f\"Processing: {src_filename}\")\n",
    "    \n",
    "    rules = retrieve_relevant_rules(code, top_k=5)\n",
    "    fixed_code = make_fixed_java(src_filename, code, rules)\n",
    "    \n",
    "    out_path = (fixed_dir / src_filename)\n",
    "    out_path.write_text(fixed_code, encoding='utf-8')\n",
    "    generated_paths.append(str(out_path))\n",
    "    print(f\"  Written: {out_path.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"File Generation Complete\")\n",
    "print(f\"Total files generated: {len(generated_paths)}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "for p in generated_paths:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification: List all generated files in the fixed directory\n",
    "print(\"\\nVerification: Files in dummy-project/fixed/\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "fixed_files = sorted(fixed_dir.glob('*.java'))\n",
    "if fixed_files:\n",
    "    print(f\"Total Java files: {len(fixed_files)}\\n\")\n",
    "    for file_path in fixed_files:\n",
    "        file_size = file_path.stat().st_size\n",
    "        print(f\"  {file_path.name:30s} ({file_size:5d} bytes)\")\n",
    "    print(\"\\nAll corrected files successfully generated\")\n",
    "else:\n",
    "    print(\"Warning: No files found in fixed directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
