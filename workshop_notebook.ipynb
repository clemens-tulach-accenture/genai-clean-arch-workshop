{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf8ef6e",
   "metadata": {},
   "source": [
    "\n",
    "# Genâ€‘AI Workshop Notebook: RAG â†’ Workflows â†’ Agents (Java Clean Architecture)\n",
    "\n",
    "**Goal:** Apply Retrieval Augmented Generation (RAG), LangChain Workflows, and Agents to detect misplaced business logic in Java code, using a small Clean Architecture knowledge base.\n",
    "\n",
    "**You will do (with minimal typing):**\n",
    "- Use a readyâ€‘made FAISS index over architecture rules\n",
    "- Implement 1â€“2 line functions in marked code frames\n",
    "- Run usage checks that apply your code to Java samples\n",
    "- See an **expected output** box before each check\n",
    "\n",
    "**Structure per exercise:**  \n",
    "**Task â†’ Coding frame (TODOs) â†’ Model solution â†’ Usage check (with expected output box).**\n",
    "\n",
    "**Prereqs (one time):**\n",
    "- Python 3.10+\n",
    "- Packages will be installed below\n",
    "- Set `OPENAI_API_KEY` (Colab: `from google.colab import userdata; os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")`)\n",
    "\n",
    "**Time guidance:** RAG (25â€“30 min) â†’ Workflows (20â€“25 min) â†’ Agents (20â€“25 min) â†’ MCP (optional, 10 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c6e4c",
   "metadata": {},
   "source": [
    "\n",
    "## Setup (run once at the top)\n",
    "\n",
    "- Install dependencies\n",
    "- Import libraries\n",
    "- Load a small Clean Architecture rule base\n",
    "- Build FAISS index (or reuse it if already built)\n",
    "- Provide Java sample snippets\n",
    "- Do a quick sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab4cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install (feel free to skip reruns if already installed)\n",
    "# If running in environments without internet/package access, keep this cell for your local/Colab run.\n",
    "try:\n",
    "    import sentence_transformers, faiss, openai, langchain\n",
    "except Exception:\n",
    "    %pip install -q sentence-transformers faiss-cpu openai langchain\n",
    "    \n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# LLM\n",
    "from openai import OpenAI\n",
    "\n",
    "# Embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Vector search\n",
    "import faiss\n",
    "\n",
    "# LangChain (chains and agents)\n",
    "from langchain.chains import LLMChain, SequentialChain, TransformChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI  # thin wrapper over OpenAI client\n",
    "\n",
    "# Misc\n",
    "import textwrap\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ---- API key expectation ----\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"âš  Please set OPENAI_API_KEY. In Colab:\")\n",
    "    print(\"from google.colab import userdata; os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\")\n",
    "\n",
    "# ---- Tiny Clean Architecture 'rule base' (demo size) ----\n",
    "# In a real workshop you would load these from files. Here we inline minimal but representative text chunks.\n",
    "chunks: List[str] = [\n",
    "    \"Controllers should delegate business rules to application or domain services; controllers handle HTTP, routing, and validation only.\",\n",
    "    \"Repositories are responsible for persistence concerns only. They should not contain business rules or calculations.\",\n",
    "    \"Entities should encapsulate core domain invariants but must not perform IO or depend on infrastructure concerns.\",\n",
    "    \"Business rules should be placed in domain services or use cases. Keep side-effects and persistence out of the domain logic.\",\n",
    "    \"Cross-cutting concerns like logging, metrics, and auth should be applied via decorators, interceptors, or middleware, not inside domain methods.\"\n",
    "]\n",
    "\n",
    "# ---- Build FAISS index ----\n",
    "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(EMBED_MODEL_NAME)\n",
    "\n",
    "emb = model.encode(chunks, convert_to_numpy=True)\n",
    "d = emb.shape[1]\n",
    "index = faiss.IndexFlatIP(d)\n",
    "# Normalize for cosine similarity via inner product\n",
    "def _normalize(x: np.ndarray) -> np.ndarray:\n",
    "    n = np.linalg.norm(x, axis=1, keepdims=True) + 1e-12\n",
    "    return x / n\n",
    "\n",
    "emb_n = _normalize(emb.copy())\n",
    "index.add(emb_n)\n",
    "\n",
    "# ---- Demo Java code samples ----\n",
    "LEAKY_SAMPLES = {\n",
    "    \"order_controller\": \"\"\"\n",
    "package com.example.leakydemo.controller;\n",
    "\n",
    "public class OrderController {\n",
    "    // Age check and discount calculation incorrectly in controller (business logic)\n",
    "    public String createOrder(User user, OrderRequest req) {\n",
    "        if (user.getAge() < 18) {  // business rule here (violation)\n",
    "            return \"Rejected: underage\";\n",
    "        }\n",
    "        double discount = 0.0;      // business rule here (violation)\n",
    "        if (req.getTotal() > 100) {\n",
    "            discount = 0.1;\n",
    "        }\n",
    "        // ... persists via service later but logic sits here\n",
    "        return \"OK\";\n",
    "    }\n",
    "}\n",
    "\"\"\",\n",
    "\n",
    "    \"order_repository\": \"\"\"\n",
    "package com.example.leakydemo.repository;\n",
    "\n",
    "public class OrderRepository {\n",
    "    // Persistence layer should not calculate discounts (violation)\n",
    "    public double saveAndReturnDiscount(double total) {\n",
    "        double discount = 0.0; // business logic (violation)\n",
    "        if (total > 100) {\n",
    "            discount = 0.1;\n",
    "        }\n",
    "        // ... pretend saving to DB ...\n",
    "        return discount;\n",
    "    }\n",
    "}\n",
    "\"\"\",\n",
    "\n",
    "    \"order_entity\": \"\"\"\n",
    "package com.example.leakydemo.domain;\n",
    "\n",
    "public class Order {\n",
    "    private double total;\n",
    "    public Order(double total) {\n",
    "        this.total = total;\n",
    "    }\n",
    "\n",
    "    // Entities should not perform IO or call repositories (violation)\n",
    "    public void ensurePersisted(OrderRepository repo) {\n",
    "        repo.save(this); // IO/infrastructure from entity (violation)\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "def preview(text: str, n=400):\n",
    "    return (text or \"\")[:n] + (\"...\" if text and len(text) > n else \"\")\n",
    "\n",
    "print(\"âœ… Setup complete. FAISS index built over\", len(chunks), \"rule chunks.\")\n",
    "print(\"âœ… Available Java samples:\", \", \".join(LEAKY_SAMPLES.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65628982",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Section 1 â€” Retrieval Augmented Generation (RAG)\n",
    "\n",
    "We implement semantic retrieval over Clean Architecture rules and then augment an LLM analysis with the retrieved context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2d9f84",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.1 â€” Implement Semantic Retrieval\n",
    "\n",
    "**Your Task:** Complete the `retrieve_relevant_rules()` function to perform semantic search on the Clean Architecture knowledge base.\n",
    "\n",
    "**What you need to implement:**\n",
    "1. Encode the query using the sentence transformer model  \n",
    "2. Search the FAISS index for topâ€‘k most similar chunks  \n",
    "3. Return the concatenated text of retrieved chunks\n",
    "\n",
    "**Success Criteria:**\n",
    "- Function returns a nonâ€‘empty string  \n",
    "- Retrieved text contains relevant architecture keywords  \n",
    "- Usage check shows controller/service/domain keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_relevant_rules(query: str, top_k: int = 3) -> str:\n",
    "    \"\"\"TODO: Implement semantic retrieval over rule chunks.\n",
    "    Steps:\n",
    "      1) query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "      2) normalize and search via FAISS (inner product)\n",
    "      3) collect chunks by indices and join\n",
    "    \"\"\"\n",
    "    # TODO: YOUR CODE HERE (minimal)\n",
    "    # hint: use _normalize and index.search\n",
    "    return \"\"  # placeholder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9542b7",
   "metadata": {},
   "source": [
    "\n",
    "**Model solution (reference implementation):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabdf7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_relevant_rules(query: str, top_k: int = 3) -> str:\n",
    "    q = model.encode([query], convert_to_numpy=True)\n",
    "    qn = _normalize(q.astype(np.float32))\n",
    "    scores, idx = index.search(qn, top_k)\n",
    "    picked = [chunks[i] for i in idx[0] if i >= 0]\n",
    "    text = \"\\n\\n\".join(picked)\n",
    "    return text.replace(\"\\u200b\", \"\").replace(\"\\ufeff\", \"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df31ae1a",
   "metadata": {},
   "source": [
    "\n",
    "**Expected output (roughly):**\n",
    "- Contains terms like *controller*, *service*, *domain*, *repositories*\n",
    "- Length clearly nonâ€‘empty (> 100 chars)\n",
    "- 2â€“3 distinct text blocks joined\n",
    "\n",
    "Now run the usage check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab750179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_query = \"business logic in controller\"\n",
    "retrieved = retrieve_relevant_rules(test_query)\n",
    "print(\"=== Retrieved rules (preview) ===\\n\")\n",
    "print(preview(retrieved, 500))\n",
    "print(\"\\nLength:\", len(retrieved))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcf8a3",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 1.2 â€” Augment LLM with Retrieved Context\n",
    "\n",
    "**Your Task:** Create a prompt that combines retrieved rules with Java code for violation analysis. Prompt text is **already provided**; your job is to call the API and return the response.\n",
    "\n",
    "**What you need to implement:**\n",
    "1. Use the provided **system** and **user** prompts\n",
    "2. Call OpenAI Chat Completions\n",
    "3. Return the response text\n",
    "\n",
    "**Success Criteria:**\n",
    "- LLM identifies at least one violation\n",
    "- Response references specific architecture rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335b6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a senior Java Clean Architecture reviewer. \"\n",
    "    \"Identify layer violations succinctly and recommend concrete fixes.\"\n",
    ")\n",
    "\n",
    "def _build_user_prompt(java_code: str, rules: str) -> str:\n",
    "    return f\"\"\"\n",
    "[Task] Analyze the Java code for Clean Architecture violations.\n",
    "[Rules]\n",
    "{rules}\n",
    "\n",
    "[Code]\n",
    "{java_code}\n",
    "\n",
    "[Output format]\n",
    "- Violations (bullet points)\n",
    "- Referenced rules (bullet points)\n",
    "- Fix recommendation (1-2 sentences)\n",
    "\"\"\"\n",
    "\n",
    "def analyze_with_rag(java_code: str, rules: str) -> str:\n",
    "    \"\"\"TODO: Call OpenAI with given prompts and return the text response.\"\"\"\n",
    "    client = OpenAI()  # expects OPENAI_API_KEY in env\n",
    "    # TODO: YOUR CODE HERE (2â€“3 lines to call chat.completions)\n",
    "    return \"\"  # placeholder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23841067",
   "metadata": {},
   "source": [
    "\n",
    "**Model solution (reference implementation):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fca1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_with_rag(java_code: str, rules: str) -> str:\n",
    "    client = OpenAI()\n",
    "    user_prompt = _build_user_prompt(java_code, rules)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return resp.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3965f6c4",
   "metadata": {},
   "source": [
    "\n",
    "**Expected output (roughly):**\n",
    "- Mentions at least one violation like *age check in controller* or *discount calculation in controller*\n",
    "- References rules (controller â†’ delegate; business rules â†’ domain/services)\n",
    "- Provides a concrete fix (move logic to service/domain)\n",
    "\n",
    "Now run the usage check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47186ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_code = LEAKY_SAMPLES['order_controller']\n",
    "rules = retrieve_relevant_rules(sample_code)\n",
    "analysis = analyze_with_rag(sample_code, rules)\n",
    "print(\"=== RAG-based analysis ===\\n\")\n",
    "print(analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62229e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Section 2 â€” Workflows with LangChain (TransformChain â†’ LLMChain â†’ SequentialChain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e5729",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 2.1 â€” Build a Sequential Chain\n",
    "\n",
    "**Your Task:** Create a `SequentialChain` that connects retrieval and analysis steps.\n",
    "\n",
    "**What you need to implement:**\n",
    "1. Define `TransformChain` for retrieval (wraps `retrieve_relevant_rules`)  \n",
    "2. Define `LLMChain` for analysis (prompt is provided)  \n",
    "3. Connect them with `SequentialChain`\n",
    "\n",
    "**Success Criteria:**\n",
    "- Workflow executes without errors\n",
    "- Output contains a violation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13304fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1 â€” Retrieval TransformChain\n",
    "def transform_retrieval(inputs: dict) -> dict:\n",
    "    \"\"\"TODO: Use retrieve_relevant_rules on inputs['code'] and return {'rules': ...}\"\"\"\n",
    "    # TODO: YOUR CODE HERE (1 line)\n",
    "    return {\"rules\": \"\"}\n",
    "\n",
    "retrieval_chain = TransformChain(\n",
    "    input_variables=[\"code\"],\n",
    "    output_variables=[\"rules\"],\n",
    "    transform=transform_retrieval\n",
    ")\n",
    "\n",
    "# Step 2 â€” Analysis LLMChain\n",
    "analysis_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Analyze the Java code for Clean Architecture violations using the given rules.\n",
    "[Rules]\n",
    "{rules}\n",
    "\n",
    "[Code]\n",
    "{code}\n",
    "\n",
    "Return:\n",
    "- Violations (bullet points)\n",
    "- Referenced rules (bullet points)\n",
    "- Fix recommendation (1-2 sentences)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "analysis_chain = LLMChain(llm=llm, prompt=analysis_template, output_key=\"analysis\")\n",
    "\n",
    "# Step 3 â€” SequentialChain\n",
    "workflow = SequentialChain(\n",
    "    # TODO: YOUR CODE HERE (fill the three arguments below)\n",
    "    chains=[],           # [retrieval_chain, analysis_chain]\n",
    "    input_variables=[],  # [\"code\"]\n",
    "    output_variables=[], # [\"analysis\"]\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39bcbc",
   "metadata": {},
   "source": [
    "\n",
    "**Model solution (reference implementation):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform_retrieval(inputs: dict) -> dict:\n",
    "    return {\"rules\": retrieve_relevant_rules(inputs[\"code\"])}\n",
    "\n",
    "retrieval_chain = TransformChain(\n",
    "    input_variables=[\"code\"],\n",
    "    output_variables=[\"rules\"],\n",
    "    transform=transform_retrieval\n",
    ")\n",
    "\n",
    "analysis_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Analyze the Java code for Clean Architecture violations using the given rules.\n",
    "[Rules]\n",
    "{rules}\n",
    "\n",
    "[Code]\n",
    "{code}\n",
    "\n",
    "Return:\n",
    "- Violations (bullet points)\n",
    "- Referenced rules (bullet points)\n",
    "- Fix recommendation (1-2 sentences)\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "analysis_chain = LLMChain(llm=llm, prompt=analysis_template, output_key=\"analysis\")\n",
    "\n",
    "workflow = SequentialChain(\n",
    "    chains=[retrieval_chain, analysis_chain],\n",
    "    input_variables=[\"code\"],\n",
    "    output_variables=[\"analysis\"],\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9af010e",
   "metadata": {},
   "source": [
    "\n",
    "**Expected output (roughly):**\n",
    "- Mentions *business logic in repository*\n",
    "- References repo rule: *repositories handle persistence only*\n",
    "- Suggests moving logic to a service/domain\n",
    "\n",
    "Now run the usage check:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7fc3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_code = LEAKY_SAMPLES['order_repository']\n",
    "result = workflow({\"code\": test_code})\n",
    "print(\"=== Workflow analysis (repository) ===\\n\")\n",
    "print(result[\"analysis\"] if isinstance(result, dict) else result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40562e75",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Section 3 â€” Agents (ReAct with a Retrieval Tool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e134b9",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 3.1 â€” Create an Agent Tool\n",
    "\n",
    "**Your Task:** Wrap the retrieval function as an agent tool and run a ReAct agent that can call it autonomously.\n",
    "\n",
    "**What you need to implement:**\n",
    "1. Define `Tool` with name, function, and description (names provided)  \n",
    "2. Initialize a ReAct agent with the tool  \n",
    "3. Provide the agent with a short input containing the Java code\n",
    "\n",
    "**Success Criteria:**\n",
    "- Agent calls the tool during execution (visible in verbose logs)\n",
    "- Agent provides a final analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd463cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n",
    "\n",
    "# Step 1 â€” Define tool (names provided)\n",
    "retrieval_tool = Tool(\n",
    "    name=\"clean_arch_retrieval\",\n",
    "    func=retrieve_relevant_rules,\n",
    "    description=\"Retrieve Clean Architecture rules relevant to the given text query.\"\n",
    ")\n",
    "\n",
    "# Step 2 â€” Initialize agent\n",
    "agent_llm = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)\n",
    "agent = initialize_agent(\n",
    "    tools=[retrieval_tool],\n",
    "    llm=agent_llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Step 3 â€” Agent input template (provided)\n",
    "agent_prompt = \"\"\"\n",
    "Analyze the following Java code for Clean Architecture violations.\n",
    "If needed, use the tool 'clean_arch_retrieval' with a suitable query.\n",
    "Provide:\n",
    "- Violations (bullet points)\n",
    "- Referenced rules (bullet points)\n",
    "- Fix recommendation (1-2 sentences)\n",
    "\n",
    "[Code]\n",
    "{code}\n",
    "\"\"\"\n",
    "\n",
    "# Usage check scaffold (run after filling above if needed)\n",
    "# result = agent.run(agent_prompt.format(code=LEAKY_SAMPLES['order_entity']))\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bfdcb",
   "metadata": {},
   "source": [
    "\n",
    "**Model solution (reference implementation):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015707aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = agent.run(agent_prompt.format(code=LEAKY_SAMPLES['order_entity']))\n",
    "print(\"=== Agent final answer (entity) ===\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49024ba",
   "metadata": {},
   "source": [
    "\n",
    "**Expected output (roughly):**\n",
    "- Mentions that the entity calls a repository/does IO (violation)\n",
    "- References rule: *entities must not perform IO or depend on infrastructure*\n",
    "- Suggests moving IO to application/service layer\n",
    "\n",
    "Note: In the verbose logs above, check that the agent used the retrieval tool at least once.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbec8cf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Section 4 â€” Model Context Protocol (MCP) via HTTP (Optional)\n",
    "\n",
    "If you have a local MCP server exposing a `tools/call` endpoint, this exercise shows a minimal async client structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dd3321",
   "metadata": {},
   "source": [
    "\n",
    "### Exercise 4.1 â€” Implement HTTP call to MCP server (SSE/JSON-RPC)\n",
    "\n",
    "**Your Task:**\n",
    "- Build the JSON-RPC request structure\n",
    "- Send a POST with `aiohttp`\n",
    "- Parse the JSON response or surface a meaningful connection error\n",
    "\n",
    "**Success Criteria:**\n",
    "- Connects if server is running\n",
    "- Otherwise prints a clear notice and confirms structure is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab40b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "async def call_mcp_server(samples_dict: dict, mcp_url: str = \"http://127.0.0.1:8765/sse\"):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {\n",
    "            \"name\": \"fix_from_json\",\n",
    "            \"arguments\": samples_dict\n",
    "        }\n",
    "    }\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(mcp_url, json=payload) as resp:\n",
    "            resp.raise_for_status()\n",
    "            return await resp.json()\n",
    "\n",
    "# Usage check (will succeed only if MCP server is available)\n",
    "async def _try_mcp():\n",
    "    try:\n",
    "        result = await call_mcp_server({\"test\": \"sample code\"})\n",
    "        print(\"âœ“ MCP connection successful!\")\n",
    "        print(json.dumps(result, indent=2)[:800])\n",
    "    except aiohttp.ClientConnectorError:\n",
    "        print(\"âš  MCP server not running (expected for demo) â€” structure OK.\")\n",
    "    except Exception as e:\n",
    "        print(\"âš  MCP call error:\", repr(e))\n",
    "\n",
    "# To run in notebooks:\n",
    "# await _try_mcp()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33573a47",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### You are done ðŸŽ‰\n",
    "- You implemented semantic retrieval, RAGâ€‘based analysis, a LangChain SequentialChain, and an Agent with a retrieval tool.\n",
    "- Reuse these patterns on larger codebases and richer rule sets.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
